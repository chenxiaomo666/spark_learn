# Spark_learn
## 概记
### 当前进度
P46/P201
### 课程信息

1.课程跟随：[尚硅谷Spark](https://www.bilibili.com/video/BV11A411L7CK)
### 遇到的坑
1.配置环境老费劲了

## 课程笔记
### 1 *********
### 2 ***********
### 3 Spark运行环境
这一章主要是讲环境配置的，然后我看了看后面，后面基本上都是用win环境做教学开发的，这一章的环境配置是在linux集群上做操作的，我觉得，刚开始学习的时候可以不太在意这个配置，虽然配置很重要，但是在工作中，这个是由运维人员配置的，作为开发人员，要把重心放在开发上，十分的合理
#### 3.1 Local模式
本地环境，不需要任何其节点资源就可以在本地执行Spark代码的环境
> 启动：/usr/local/spark/bin/spark-shell
> 关闭：
### 3.2 Standalone模式
* 可以配置历史记录-历史服务
### 3.3 Yarn模式
企业常用的
### 4 Spark运行架构
Driver是驱动器节点，用于执行spark任务中的main方法，
Executor是执行的节点，

#### 4.3 核心概念
##### 4.3.1 Executor与Core

### 5 Spark核心编程
三个数据结构：
* RDD：弹性分布式数据集
* 累加器：分布式共享只写变量（只写？不可以读嘛？）
* 广播变量：分布式共享只读变量

#### 5.1 RDD
* 代表一个弹性的，不可变，可分区，里面的元素可并行计算，
* 只有调用collect方法的时候，才进行业务操作，类似于lazy模式，
* RDD不保存数据，IO可以临时保存一部分数据，
* 内存和硬盘存储切换、数据丢失可以自动恢复、计算出错，重试机制、可根据分片重新计算；
* 数据存储在大数据不同节点上；
* RDD封存数据集，不保存数据只是封装计算逻辑；
* RDD是一个抽象类，需要子类具体实现；
* RDD封装了计算逻辑，是不可以改变的，要想改变，只能产生新的RDD，在新的RDD里面封装新的逻辑；
* 可分区，并行计算；
* 移动数据不如移动计算，数据不移动；
* RDD主要是用于讲逻辑进行封装，并生成Task发送给Executor节点进行计算；

##### RDD转换算子
###### 1. Value类型

